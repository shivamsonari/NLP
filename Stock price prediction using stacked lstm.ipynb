{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>adjClose</th>\n",
       "      <th>adjHigh</th>\n",
       "      <th>adjLow</th>\n",
       "      <th>adjOpen</th>\n",
       "      <th>adjVolume</th>\n",
       "      <th>divCash</th>\n",
       "      <th>splitFactor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-05-27 00:00:00+00:00</td>\n",
       "      <td>132.045</td>\n",
       "      <td>132.260</td>\n",
       "      <td>130.05</td>\n",
       "      <td>130.34</td>\n",
       "      <td>45833246</td>\n",
       "      <td>121.682558</td>\n",
       "      <td>121.880685</td>\n",
       "      <td>119.844118</td>\n",
       "      <td>120.111360</td>\n",
       "      <td>45833246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-05-28 00:00:00+00:00</td>\n",
       "      <td>131.780</td>\n",
       "      <td>131.950</td>\n",
       "      <td>131.10</td>\n",
       "      <td>131.86</td>\n",
       "      <td>30733309</td>\n",
       "      <td>121.438354</td>\n",
       "      <td>121.595013</td>\n",
       "      <td>120.811718</td>\n",
       "      <td>121.512076</td>\n",
       "      <td>30733309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-05-29 00:00:00+00:00</td>\n",
       "      <td>130.280</td>\n",
       "      <td>131.450</td>\n",
       "      <td>129.90</td>\n",
       "      <td>131.23</td>\n",
       "      <td>50884452</td>\n",
       "      <td>120.056069</td>\n",
       "      <td>121.134251</td>\n",
       "      <td>119.705890</td>\n",
       "      <td>120.931516</td>\n",
       "      <td>50884452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-06-01 00:00:00+00:00</td>\n",
       "      <td>130.535</td>\n",
       "      <td>131.390</td>\n",
       "      <td>130.05</td>\n",
       "      <td>131.20</td>\n",
       "      <td>32112797</td>\n",
       "      <td>120.291057</td>\n",
       "      <td>121.078960</td>\n",
       "      <td>119.844118</td>\n",
       "      <td>120.903870</td>\n",
       "      <td>32112797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-06-02 00:00:00+00:00</td>\n",
       "      <td>129.960</td>\n",
       "      <td>130.655</td>\n",
       "      <td>129.32</td>\n",
       "      <td>129.86</td>\n",
       "      <td>33667627</td>\n",
       "      <td>119.761181</td>\n",
       "      <td>120.401640</td>\n",
       "      <td>119.171406</td>\n",
       "      <td>119.669029</td>\n",
       "      <td>33667627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 symbol                       date    close     high     low  \\\n",
       "0           0   AAPL  2015-05-27 00:00:00+00:00  132.045  132.260  130.05   \n",
       "1           1   AAPL  2015-05-28 00:00:00+00:00  131.780  131.950  131.10   \n",
       "2           2   AAPL  2015-05-29 00:00:00+00:00  130.280  131.450  129.90   \n",
       "3           3   AAPL  2015-06-01 00:00:00+00:00  130.535  131.390  130.05   \n",
       "4           4   AAPL  2015-06-02 00:00:00+00:00  129.960  130.655  129.32   \n",
       "\n",
       "     open    volume    adjClose     adjHigh      adjLow     adjOpen  \\\n",
       "0  130.34  45833246  121.682558  121.880685  119.844118  120.111360   \n",
       "1  131.86  30733309  121.438354  121.595013  120.811718  121.512076   \n",
       "2  131.23  50884452  120.056069  121.134251  119.705890  120.931516   \n",
       "3  131.20  32112797  120.291057  121.078960  119.844118  120.903870   \n",
       "4  129.86  33667627  119.761181  120.401640  119.171406  119.669029   \n",
       "\n",
       "   adjVolume  divCash  splitFactor  \n",
       "0   45833246      0.0          1.0  \n",
       "1   30733309      0.0          1.0  \n",
       "2   50884452      0.0          1.0  \n",
       "3   32112797      0.0          1.0  \n",
       "4   33667627      0.0          1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.reset_index()['close']  ## Take the close column and index it 0-1257 accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       132.045\n",
       "1       131.780\n",
       "2       130.280\n",
       "3       130.535\n",
       "4       129.960\n",
       "         ...   \n",
       "1253    314.960\n",
       "1254    313.140\n",
       "1255    319.230\n",
       "1256    316.850\n",
       "1257    318.890\n",
       "Name: close, Length: 1258, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e8989d3308>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM are sensitive to the scale of the data. so we apply MinMax scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17607447],\n",
       "       [0.17495567],\n",
       "       [0.16862282],\n",
       "       ...,\n",
       "       [0.96635143],\n",
       "       [0.9563033 ],\n",
       "       [0.96491598]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##splitting dataset into train and test split\n",
    "training_size=int(len(df1)*0.65)             ### Initial 65 % data will be training because it is time series problem\n",
    "test_size=len(df1)-training_size  \n",
    "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817, 441)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size,test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17607447],\n",
       "       [0.17495567],\n",
       "       [0.16862282],\n",
       "       [0.1696994 ],\n",
       "       [0.16727181],\n",
       "       [0.16794731],\n",
       "       [0.16473866],\n",
       "       [0.16174111],\n",
       "       [0.1581525 ],\n",
       "       [0.15654817],\n",
       "       [0.16271215],\n",
       "       [0.1614878 ],\n",
       "       [0.1554927 ],\n",
       "       [0.15443722],\n",
       "       [0.15730811],\n",
       "       [0.15604154],\n",
       "       [0.15849025],\n",
       "       [0.15308621],\n",
       "       [0.15735033],\n",
       "       [0.15490163],\n",
       "       [0.15946129],\n",
       "       [0.15688592],\n",
       "       [0.1537195 ],\n",
       "       [0.14434687],\n",
       "       [0.14812547],\n",
       "       [0.15308621],\n",
       "       [0.15241071],\n",
       "       [0.15055307],\n",
       "       [0.14924428],\n",
       "       [0.13607194],\n",
       "       [0.12551718],\n",
       "       [0.13906949],\n",
       "       [0.14911762],\n",
       "       [0.14890653],\n",
       "       [0.15401503],\n",
       "       [0.16115005],\n",
       "       [0.16583636],\n",
       "       [0.17618002],\n",
       "       [0.17060711],\n",
       "       [0.14725998],\n",
       "       [0.14700667],\n",
       "       [0.14422021],\n",
       "       [0.13691632],\n",
       "       [0.13949168],\n",
       "       [0.13784514],\n",
       "       [0.13522756],\n",
       "       [0.13071012],\n",
       "       [0.11863548],\n",
       "       [0.10259225],\n",
       "       [0.1058009 ],\n",
       "       [0.10466098],\n",
       "       [0.10630752],\n",
       "       [0.12403952],\n",
       "       [0.09773706],\n",
       "       [0.10512539],\n",
       "       [0.10474542],\n",
       "       [0.10816516],\n",
       "       [0.11323144],\n",
       "       [0.11044499],\n",
       "       [0.10415435],\n",
       "       [0.09419066],\n",
       "       [0.06510175],\n",
       "       [0.05395592],\n",
       "       [0.0565735 ],\n",
       "       [0.08169383],\n",
       "       [0.09533058],\n",
       "       [0.09689268],\n",
       "       [0.09465507],\n",
       "       [0.07337668],\n",
       "       [0.09288187],\n",
       "       [0.08456472],\n",
       "       [0.07992063],\n",
       "       [0.09275521],\n",
       "       [0.0836359 ],\n",
       "       [0.09385291],\n",
       "       [0.10077683],\n",
       "       [0.10542092],\n",
       "       [0.10951617],\n",
       "       [0.11006502],\n",
       "       [0.09955248],\n",
       "       [0.09756818],\n",
       "       [0.10499873],\n",
       "       [0.09735709],\n",
       "       [0.10124124],\n",
       "       [0.10411213],\n",
       "       [0.10288778],\n",
       "       [0.09330406],\n",
       "       [0.07903403],\n",
       "       [0.08426919],\n",
       "       [0.08122942],\n",
       "       [0.08460694],\n",
       "       [0.0862957 ],\n",
       "       [0.08853331],\n",
       "       [0.0862957 ],\n",
       "       [0.08089167],\n",
       "       [0.09195305],\n",
       "       [0.08975766],\n",
       "       [0.09055982],\n",
       "       [0.08388922],\n",
       "       [0.09085536],\n",
       "       [0.0873934 ],\n",
       "       [0.09030651],\n",
       "       [0.09891919],\n",
       "       [0.09887697],\n",
       "       [0.10622309],\n",
       "       [0.1213375 ],\n",
       "       [0.10529427],\n",
       "       [0.10221228],\n",
       "       [0.12213966],\n",
       "       [0.12745926],\n",
       "       [0.1231107 ],\n",
       "       [0.1302035 ],\n",
       "       [0.13607194],\n",
       "       [0.13366546],\n",
       "       [0.1291058 ],\n",
       "       [0.12969687],\n",
       "       [0.12762813],\n",
       "       [0.1115849 ],\n",
       "       [0.10879845],\n",
       "       [0.1071519 ],\n",
       "       [0.09288187],\n",
       "       [0.10062906],\n",
       "       [0.09858144],\n",
       "       [0.11378029],\n",
       "       [0.12007093],\n",
       "       [0.12226632],\n",
       "       [0.11572237],\n",
       "       [0.12049312],\n",
       "       [0.1169045 ],\n",
       "       [0.11597568],\n",
       "       [0.11804441],\n",
       "       [0.11399139],\n",
       "       [0.10951617],\n",
       "       [0.10495651],\n",
       "       [0.1211264 ],\n",
       "       [0.11795998],\n",
       "       [0.11774888],\n",
       "       [0.10672971],\n",
       "       [0.10905176],\n",
       "       [0.09642827],\n",
       "       [0.09347294],\n",
       "       [0.08507135],\n",
       "       [0.08865997],\n",
       "       [0.07869628],\n",
       "       [0.06624166],\n",
       "       [0.07173014],\n",
       "       [0.07130795],\n",
       "       [0.07713417],\n",
       "       [0.07468547],\n",
       "       [0.06957697],\n",
       "       [0.07768302],\n",
       "       [0.07168792],\n",
       "       [0.0629908 ],\n",
       "       [0.06337077],\n",
       "       [0.05222494],\n",
       "       [0.04373892],\n",
       "       [0.02579583],\n",
       "       [0.027949  ],\n",
       "       [0.03457739],\n",
       "       [0.04061471],\n",
       "       [0.02976442],\n",
       "       [0.03875707],\n",
       "       [0.02866672],\n",
       "       [0.02668243],\n",
       "       [0.02723128],\n",
       "       [0.02516254],\n",
       "       [0.04677869],\n",
       "       [0.03841932],\n",
       "       [0.04074137],\n",
       "       [0.01300346],\n",
       "       [0.01583214],\n",
       "       [0.02955332],\n",
       "       [0.02571139],\n",
       "       [0.01747868],\n",
       "       [0.02537364],\n",
       "       [0.02642911],\n",
       "       [0.0155366 ],\n",
       "       [0.01971629],\n",
       "       [0.01963185],\n",
       "       [0.01659208],\n",
       "       [0.01418559],\n",
       "       [0.01540995],\n",
       "       [0.02659799],\n",
       "       [0.03284641],\n",
       "       [0.02499367],\n",
       "       [0.02406485],\n",
       "       [0.02761125],\n",
       "       [0.01836528],\n",
       "       [0.02431816],\n",
       "       [0.02710462],\n",
       "       [0.0277379 ],\n",
       "       [0.02680909],\n",
       "       [0.04302119],\n",
       "       [0.04395001],\n",
       "       [0.04711644],\n",
       "       [0.05349151],\n",
       "       [0.04867854],\n",
       "       [0.04513215],\n",
       "       [0.04551212],\n",
       "       [0.04572321],\n",
       "       [0.05032509],\n",
       "       [0.05142278],\n",
       "       [0.0601199 ],\n",
       "       [0.06598835],\n",
       "       [0.06527062],\n",
       "       [0.06577725],\n",
       "       [0.06573503],\n",
       "       [0.06915477],\n",
       "       [0.06666385],\n",
       "       [0.06472178],\n",
       "       [0.06269526],\n",
       "       [0.0732078 ],\n",
       "       [0.08114498],\n",
       "       [0.0787385 ],\n",
       "       [0.0829604 ],\n",
       "       [0.08773115],\n",
       "       [0.08220046],\n",
       "       [0.08705564],\n",
       "       [0.07683864],\n",
       "       [0.07734527],\n",
       "       [0.07886515],\n",
       "       [0.08486026],\n",
       "       [0.0916153 ],\n",
       "       [0.09186861],\n",
       "       [0.08236933],\n",
       "       [0.07236342],\n",
       "       [0.06995694],\n",
       "       [0.07088576],\n",
       "       [0.06598835],\n",
       "       [0.064764  ],\n",
       "       [0.06223085],\n",
       "       [0.05914886],\n",
       "       [0.03157984],\n",
       "       [0.01895635],\n",
       "       [0.01435447],\n",
       "       [0.01393228],\n",
       "       [0.02043401],\n",
       "       [0.01625433],\n",
       "       [0.01224352],\n",
       "       [0.01004813],\n",
       "       [0.01034366],\n",
       "       [0.01300346],\n",
       "       [0.00916153],\n",
       "       [0.        ],\n",
       "       [0.00075994],\n",
       "       [0.01494554],\n",
       "       [0.013299  ],\n",
       "       [0.01781643],\n",
       "       [0.01629655],\n",
       "       [0.02060289],\n",
       "       [0.02571139],\n",
       "       [0.03191759],\n",
       "       [0.03917926],\n",
       "       [0.04251457],\n",
       "       [0.04226125],\n",
       "       [0.04019252],\n",
       "       [0.03428185],\n",
       "       [0.03115765],\n",
       "       [0.03200203],\n",
       "       [0.03499958],\n",
       "       [0.03668834],\n",
       "       [0.03630837],\n",
       "       [0.03930592],\n",
       "       [0.03584396],\n",
       "       [0.02955332],\n",
       "       [0.03005995],\n",
       "       [0.02870894],\n",
       "       [0.03043992],\n",
       "       [0.0210673 ],\n",
       "       [0.02009626],\n",
       "       [0.023516  ],\n",
       "       [0.02199612],\n",
       "       [0.02431816],\n",
       "       [0.01291902],\n",
       "       [0.00717724],\n",
       "       [0.01372119],\n",
       "       [0.01714093],\n",
       "       [0.02220721],\n",
       "       [0.02343156],\n",
       "       [0.01963185],\n",
       "       [0.02191168],\n",
       "       [0.02364266],\n",
       "       [0.02676687],\n",
       "       [0.02803344],\n",
       "       [0.02989107],\n",
       "       [0.02756903],\n",
       "       [0.03567508],\n",
       "       [0.03563286],\n",
       "       [0.04006586],\n",
       "       [0.04023474],\n",
       "       [0.04061471],\n",
       "       [0.0383771 ],\n",
       "       [0.03512623],\n",
       "       [0.02955332],\n",
       "       [0.02672465],\n",
       "       [0.0532382 ],\n",
       "       [0.05910665],\n",
       "       [0.0585578 ],\n",
       "       [0.0663261 ],\n",
       "       [0.05969771],\n",
       "       [0.0652284 ],\n",
       "       [0.06556616],\n",
       "       [0.07236342],\n",
       "       [0.07612092],\n",
       "       [0.07797855],\n",
       "       [0.07455881],\n",
       "       [0.07426328],\n",
       "       [0.07531875],\n",
       "       [0.08080723],\n",
       "       [0.08038504],\n",
       "       [0.07970953],\n",
       "       [0.07911847],\n",
       "       [0.0803006 ],\n",
       "       [0.07671198],\n",
       "       [0.07814743],\n",
       "       [0.07468547],\n",
       "       [0.07274339],\n",
       "       [0.07008359],\n",
       "       [0.06957697],\n",
       "       [0.066115  ],\n",
       "       [0.06653719],\n",
       "       [0.06919699],\n",
       "       [0.0734189 ],\n",
       "       [0.07329224],\n",
       "       [0.0760787 ],\n",
       "       [0.06408849],\n",
       "       [0.05399814],\n",
       "       [0.06375074],\n",
       "       [0.07434772],\n",
       "       [0.09047539],\n",
       "       [0.10651862],\n",
       "       [0.10377438],\n",
       "       [0.09811703],\n",
       "       [0.09807481],\n",
       "       [0.09799037],\n",
       "       [0.10250781],\n",
       "       [0.09444398],\n",
       "       [0.0951617 ],\n",
       "       [0.0960483 ],\n",
       "       [0.09967914],\n",
       "       [0.09220637],\n",
       "       [0.09587942],\n",
       "       [0.09364181],\n",
       "       [0.09566833],\n",
       "       [0.09587942],\n",
       "       [0.09942582],\n",
       "       [0.10014354],\n",
       "       [0.10854513],\n",
       "       [0.10960061],\n",
       "       [0.11399139],\n",
       "       [0.1124715 ],\n",
       "       [0.11521574],\n",
       "       [0.11487799],\n",
       "       [0.11454023],\n",
       "       [0.11306257],\n",
       "       [0.11280925],\n",
       "       [0.11086718],\n",
       "       [0.11530018],\n",
       "       [0.11783332],\n",
       "       [0.10660306],\n",
       "       [0.10191674],\n",
       "       [0.0987081 ],\n",
       "       [0.09794816],\n",
       "       [0.08929325],\n",
       "       [0.08971544],\n",
       "       [0.08228489],\n",
       "       [0.07810521],\n",
       "       [0.0847336 ],\n",
       "       [0.08747784],\n",
       "       [0.08671789],\n",
       "       [0.07367221],\n",
       "       [0.07637423],\n",
       "       [0.06489065],\n",
       "       [0.07080132],\n",
       "       [0.0829604 ],\n",
       "       [0.08279152],\n",
       "       [0.08325593],\n",
       "       [0.09030651],\n",
       "       [0.09060204],\n",
       "       [0.08819556],\n",
       "       [0.09055982],\n",
       "       [0.08963101],\n",
       "       [0.0891666 ],\n",
       "       [0.08519801],\n",
       "       [0.08084945],\n",
       "       [0.08258043],\n",
       "       [0.07924512],\n",
       "       [0.08279152],\n",
       "       [0.08735118],\n",
       "       [0.09195305],\n",
       "       [0.09967914],\n",
       "       [0.0969349 ],\n",
       "       [0.1049143 ],\n",
       "       [0.1049143 ],\n",
       "       [0.10757409],\n",
       "       [0.10820738],\n",
       "       [0.11103606],\n",
       "       [0.11234485],\n",
       "       [0.11280925],\n",
       "       [0.10955839],\n",
       "       [0.11052943],\n",
       "       [0.11365364],\n",
       "       [0.11154268],\n",
       "       [0.11141603],\n",
       "       [0.10757409],\n",
       "       [0.10896732],\n",
       "       [0.10841848],\n",
       "       [0.1109094 ],\n",
       "       [0.11639787],\n",
       "       [0.12095753],\n",
       "       [0.12146416],\n",
       "       [0.12416617],\n",
       "       [0.12205522],\n",
       "       [0.12116862],\n",
       "       [0.12522165],\n",
       "       [0.12517943],\n",
       "       [0.12429283],\n",
       "       [0.12522165],\n",
       "       [0.1255594 ],\n",
       "       [0.12509499],\n",
       "       [0.13315883],\n",
       "       [0.13341214],\n",
       "       [0.13345436],\n",
       "       [0.13210335],\n",
       "       [0.13092122],\n",
       "       [0.1621633 ],\n",
       "       [0.16123448],\n",
       "       [0.16355653],\n",
       "       [0.16866503],\n",
       "       [0.17390019],\n",
       "       [0.17605336],\n",
       "       [0.17765769],\n",
       "       [0.17639112],\n",
       "       [0.18133074],\n",
       "       [0.18863464],\n",
       "       [0.19070337],\n",
       "       [0.19000676],\n",
       "       [0.19158997],\n",
       "       [0.19572743],\n",
       "       [0.19745841],\n",
       "       [0.19500971],\n",
       "       [0.19555856],\n",
       "       [0.19669847],\n",
       "       [0.19695179],\n",
       "       [0.20877311],\n",
       "       [0.20526894],\n",
       "       [0.2087309 ],\n",
       "       [0.20687326],\n",
       "       [0.2076332 ],\n",
       "       [0.20543781],\n",
       "       [0.2040868 ],\n",
       "       [0.20602888],\n",
       "       [0.20628219],\n",
       "       [0.20539559],\n",
       "       [0.21160179],\n",
       "       [0.21257283],\n",
       "       [0.2096175 ],\n",
       "       [0.21582369],\n",
       "       [0.20898421],\n",
       "       [0.21565482],\n",
       "       [0.21354387],\n",
       "       [0.21236173],\n",
       "       [0.21337499],\n",
       "       [0.22570295],\n",
       "       [0.22705396],\n",
       "       [0.22625179],\n",
       "       [0.22511188],\n",
       "       [0.22528076],\n",
       "       [0.22979819],\n",
       "       [0.22663177],\n",
       "       [0.22511188],\n",
       "       [0.22376087],\n",
       "       [0.22304315],\n",
       "       [0.21654142],\n",
       "       [0.21725914],\n",
       "       [0.21409271],\n",
       "       [0.2173858 ],\n",
       "       [0.214726  ],\n",
       "       [0.21253061],\n",
       "       [0.21996116],\n",
       "       [0.21924343],\n",
       "       [0.22502744],\n",
       "       [0.22878494],\n",
       "       [0.22519632],\n",
       "       [0.22566073],\n",
       "       [0.22506966],\n",
       "       [0.23743984],\n",
       "       [0.24136621],\n",
       "       [0.23946635],\n",
       "       [0.23722874],\n",
       "       [0.24748797],\n",
       "       [0.26458668],\n",
       "       [0.26872414],\n",
       "       [0.26564215],\n",
       "       [0.26855526],\n",
       "       [0.27763236],\n",
       "       [0.2759436 ],\n",
       "       [0.27497256],\n",
       "       [0.25293422],\n",
       "       [0.26260238],\n",
       "       [0.26479777],\n",
       "       [0.26872414],\n",
       "       [0.26792198],\n",
       "       [0.2659799 ],\n",
       "       [0.26821751],\n",
       "       [0.26711982],\n",
       "       [0.26737313],\n",
       "       [0.2635312 ],\n",
       "       [0.2653044 ],\n",
       "       [0.27488812],\n",
       "       [0.26847083],\n",
       "       [0.27066622],\n",
       "       [0.27455037],\n",
       "       [0.27294604],\n",
       "       [0.24757241],\n",
       "       [0.23254243],\n",
       "       [0.23748206],\n",
       "       [0.23144474],\n",
       "       [0.22777168],\n",
       "       [0.21924343],\n",
       "       [0.23642658],\n",
       "       [0.23081145],\n",
       "       [0.23444229],\n",
       "       [0.23342903],\n",
       "       [0.23617327],\n",
       "       [0.23423119],\n",
       "       [0.22540741],\n",
       "       [0.23427341],\n",
       "       [0.22519632],\n",
       "       [0.22663177],\n",
       "       [0.22443638],\n",
       "       [0.2269273 ],\n",
       "       [0.22118551],\n",
       "       [0.22730727],\n",
       "       [0.23102254],\n",
       "       [0.23300684],\n",
       "       [0.23389344],\n",
       "       [0.2424639 ],\n",
       "       [0.24782572],\n",
       "       [0.25002111],\n",
       "       [0.2522165 ],\n",
       "       [0.25618509],\n",
       "       [0.25331419],\n",
       "       [0.25301866],\n",
       "       [0.26070252],\n",
       "       [0.26344676],\n",
       "       [0.26648653],\n",
       "       [0.25424301],\n",
       "       [0.2497678 ],\n",
       "       [0.24651693],\n",
       "       [0.25208984],\n",
       "       [0.28202314],\n",
       "       [0.27539475],\n",
       "       [0.27885671],\n",
       "       [0.28907371],\n",
       "       [0.29443553],\n",
       "       [0.298573  ],\n",
       "       [0.27433927],\n",
       "       [0.28345858],\n",
       "       [0.29346449],\n",
       "       [0.30085282],\n",
       "       [0.29810859],\n",
       "       [0.28506291],\n",
       "       [0.28354302],\n",
       "       [0.28231867],\n",
       "       [0.29316896],\n",
       "       [0.29401334],\n",
       "       [0.29101579],\n",
       "       [0.29350671],\n",
       "       [0.30030398],\n",
       "       [0.30638352],\n",
       "       [0.30824116],\n",
       "       [0.31098539],\n",
       "       [0.31119649],\n",
       "       [0.30287934],\n",
       "       [0.30216161],\n",
       "       [0.29941738],\n",
       "       [0.28831377],\n",
       "       [0.30043063],\n",
       "       [0.29772862],\n",
       "       [0.29262011],\n",
       "       [0.28683611],\n",
       "       [0.29359115],\n",
       "       [0.28848265],\n",
       "       [0.28873596],\n",
       "       [0.2775057 ],\n",
       "       [0.266191  ],\n",
       "       [0.25985814],\n",
       "       [0.25420079],\n",
       "       [0.26513552],\n",
       "       [0.2697374 ],\n",
       "       [0.26572659],\n",
       "       [0.26927299],\n",
       "       [0.2679642 ],\n",
       "       [0.27079287],\n",
       "       [0.26657097],\n",
       "       [0.27463481],\n",
       "       [0.27425483],\n",
       "       [0.27653466],\n",
       "       [0.27678798],\n",
       "       [0.27953221],\n",
       "       [0.27721017],\n",
       "       [0.28138985],\n",
       "       [0.29359115],\n",
       "       [0.29608207],\n",
       "       [0.29308452],\n",
       "       [0.27712573],\n",
       "       [0.27826564],\n",
       "       [0.27792789],\n",
       "       [0.28185426],\n",
       "       [0.27894115],\n",
       "       [0.28316305],\n",
       "       [0.30697458],\n",
       "       [0.32246897],\n",
       "       [0.33226378],\n",
       "       [0.32318669],\n",
       "       [0.32833741],\n",
       "       [0.34687157],\n",
       "       [0.3542599 ],\n",
       "       [0.35662417],\n",
       "       [0.36266149],\n",
       "       [0.3611416 ],\n",
       "       [0.3560331 ],\n",
       "       [0.35307777],\n",
       "       [0.34197416],\n",
       "       [0.33243266],\n",
       "       [0.34096091],\n",
       "       [0.3369501 ],\n",
       "       [0.33623237],\n",
       "       [0.34957359],\n",
       "       [0.35725745],\n",
       "       [0.35729967],\n",
       "       [0.3535844 ],\n",
       "       [0.34927805],\n",
       "       [0.33412142],\n",
       "       [0.34412733],\n",
       "       [0.34074981],\n",
       "       [0.33547243],\n",
       "       [0.33479693],\n",
       "       [0.33213713],\n",
       "       [0.33344592],\n",
       "       [0.33365701],\n",
       "       [0.34758929],\n",
       "       [0.34349405],\n",
       "       [0.34590053],\n",
       "       [0.34568944],\n",
       "       [0.35307777],\n",
       "       [0.36342143],\n",
       "       [0.35548425],\n",
       "       [0.35468209],\n",
       "       [0.35746855],\n",
       "       [0.35746855],\n",
       "       [0.3387233 ],\n",
       "       [0.33884995],\n",
       "       [0.34087647],\n",
       "       [0.33306595],\n",
       "       [0.34585831],\n",
       "       [0.34573166],\n",
       "       [0.34910918],\n",
       "       [0.35742633],\n",
       "       [0.35468209],\n",
       "       [0.35459765],\n",
       "       [0.35442878],\n",
       "       [0.35860846],\n",
       "       [0.36625011],\n",
       "       [0.36245039],\n",
       "       [0.37473613],\n",
       "       [0.37541164],\n",
       "       [0.37203411],\n",
       "       [0.36587013],\n",
       "       [0.36603901],\n",
       "       [0.35413324],\n",
       "       [0.34100312],\n",
       "       [0.34269189],\n",
       "       [0.32770413],\n",
       "       [0.32352444],\n",
       "       [0.32546652],\n",
       "       [0.32694419],\n",
       "       [0.29620873],\n",
       "       [0.2792789 ],\n",
       "       [0.30689015],\n",
       "       [0.2921557 ],\n",
       "       [0.27362155],\n",
       "       [0.27894115],\n",
       "       [0.30553914],\n",
       "       [0.31242084],\n",
       "       [0.32521321],\n",
       "       [0.3489403 ],\n",
       "       [0.34657604],\n",
       "       [0.34412733],\n",
       "       [0.34083425],\n",
       "       [0.34687157],\n",
       "       [0.35953728],\n",
       "       [0.37418728],\n",
       "       [0.37173858],\n",
       "       [0.37059867],\n",
       "       [0.35742633],\n",
       "       [0.36253483],\n",
       "       [0.36511019],\n",
       "       [0.36447691],\n",
       "       [0.35755298],\n",
       "       [0.36561682],\n",
       "       [0.37845141],\n",
       "       [0.38579752],\n",
       "       [0.37840919],\n",
       "       [0.37194967],\n",
       "       [0.37283627],\n",
       "       [0.37017648],\n",
       "       [0.3586929 ],\n",
       "       [0.35843958],\n",
       "       [0.34167863],\n",
       "       [0.33146162],\n",
       "       [0.31495398],\n",
       "       [0.34801148],\n",
       "       [0.32930845],\n",
       "       [0.32145571],\n",
       "       [0.32694419],\n",
       "       [0.32230009],\n",
       "       [0.32951955],\n",
       "       [0.34311408],\n",
       "       [0.34813814],\n",
       "       [0.32947733],\n",
       "       [0.33652791],\n",
       "       [0.350038  ],\n",
       "       [0.34661826],\n",
       "       [0.35379549],\n",
       "       [0.35628641],\n",
       "       [0.36088829],\n",
       "       [0.37110529],\n",
       "       [0.36941653],\n",
       "       [0.34813814],\n",
       "       [0.31824707],\n",
       "       [0.31622055],\n",
       "       [0.30651017],\n",
       "       [0.30950773],\n",
       "       [0.31191421],\n",
       "       [0.30389259],\n",
       "       [0.31630499],\n",
       "       [0.3325171 ],\n",
       "       [0.36405472],\n",
       "       [0.36540572],\n",
       "       [0.39470573],\n",
       "       [0.40032086],\n",
       "       [0.40407836],\n",
       "       [0.40960905],\n",
       "       [0.42092375],\n",
       "       [0.41480199],\n",
       "       [0.41294436],\n",
       "       [0.4057249 ],\n",
       "       [0.41307101],\n",
       "       [0.40804695],\n",
       "       [0.40517605],\n",
       "       [0.41074897],\n",
       "       [0.40876467],\n",
       "       [0.41383095],\n",
       "       [0.41294436],\n",
       "       [0.41475977],\n",
       "       [0.41188888],\n",
       "       [0.41020012],\n",
       "       [0.40754032],\n",
       "       [0.42176813],\n",
       "       [0.42848096],\n",
       "       [0.43472938],\n",
       "       [0.43755805],\n",
       "       [0.43536266],\n",
       "       [0.42793211],\n",
       "       [0.42594782],\n",
       "       [0.43038082],\n",
       "       [0.42371021],\n",
       "       [0.4241324 ],\n",
       "       [0.41585747],\n",
       "       [0.41543528],\n",
       "       [0.40255847],\n",
       "       [0.40597821],\n",
       "       [0.40158744],\n",
       "       [0.39930761],\n",
       "       [0.38769737],\n",
       "       [0.39723888],\n",
       "       [0.39609896],\n",
       "       [0.40175631],\n",
       "       [0.40010977],\n",
       "       [0.40884911],\n",
       "       [0.3950857 ],\n",
       "       [0.40133412],\n",
       "       [0.41218441],\n",
       "       [0.42320358],\n",
       "       [0.42223254],\n",
       "       [0.41180444],\n",
       "       [0.42510344],\n",
       "       [0.42637001],\n",
       "       [0.42459681],\n",
       "       [0.42687664],\n",
       "       [0.42244364],\n",
       "       [0.42869205],\n",
       "       [0.42683442],\n",
       "       [0.42755214],\n",
       "       [0.43342059],\n",
       "       [0.44110445],\n",
       "       [0.43852909],\n",
       "       [0.42489234],\n",
       "       [0.42037491],\n",
       "       [0.42197923],\n",
       "       [0.46930676],\n",
       "       [0.49417377],\n",
       "       [0.49670692],\n",
       "       [0.50126657],\n",
       "       [0.49299164],\n",
       "       [0.49358271],\n",
       "       [0.50046441],\n",
       "       [0.49476484],\n",
       "       [0.50042219],\n",
       "       [0.50413747],\n",
       "       [0.5062062 ],\n",
       "       [0.51920966],\n",
       "       [0.53719497],\n",
       "       [0.52824453],\n",
       "       [0.52647133]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step-1):\n",
    "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
    "time_step = 100\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, ytest = create_dataset(test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the Stacked LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(50,return_sequences=True,input_shape=(80,1)))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 80, 50)            10400     \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 80, 50)            20200     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 50,851\n",
      "Trainable params: 50,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\n        self.name)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 100]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-7a952aa495dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[1;32m-> 3142\u001b[1;33m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\n        self.name)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 100]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=50,batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\n        self.name)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 100]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-7e290efa0358>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Lets Do the prediction and check performance metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_predict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_predict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[1;32m-> 3142\u001b[1;33m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\n        self.name)\n    D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 100]\n"
     ]
    }
   ],
   "source": [
    "### Lets Do the prediction and check performance metrics\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
